# LLaMA Factory Training Configuration: VGPT2 V4 SFT
#
# This configuration uses the schema-in-prompt training data
# generated by the V4 pipeline.
#
# Usage:
#   llamafactory-cli train examples/train_lora/vgpt2_v4_sft.yaml
#
# Prerequisites:
#   1. Generate V4 training data:
#      python scripts/vgpt2_v4/run_pipeline.py
#   2. Register dataset in data/dataset_info.json

### Model
model_name_or_path: Qwen/Qwen2.5-7B-Instruct

### Method
stage: sft
do_train: true
finetuning_type: lora
lora_target: all
lora_rank: 64
lora_alpha: 128
lora_dropout: 0.05

### Dataset
dataset: vgpt2_v4_sft
template: qwen
cutoff_len: 4096  # Increased for schema-in-prompt format
max_samples: 3000
overwrite_cache: true
preprocessing_num_workers: 4

### Output
output_dir: saves/vgpt2_v4/sft
logging_steps: 10
save_steps: 500
plot_loss: true
overwrite_output_dir: true

### Training
per_device_train_batch_size: 2
gradient_accumulation_steps: 8
learning_rate: 2.0e-5
num_train_epochs: 3.0
lr_scheduler_type: cosine
warmup_ratio: 0.1
bf16: true
ddp_timeout: 180000000

### Evaluation (optional)
# val_size: 0.05
# per_device_eval_batch_size: 2
# eval_strategy: steps
# eval_steps: 500
